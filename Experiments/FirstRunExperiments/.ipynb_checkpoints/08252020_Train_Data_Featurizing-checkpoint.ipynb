{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-08-2020:12:23:01,736 INFO     [file_utils.py:39] PyTorch version 1.4.0 available.\n",
      "25-08-2020:12:23:01,737 INFO     [file_utils.py:55] TensorFlow version 2.2.0 available.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/nissani/Desktop/Hateful_Memes_Project/LoadingData')\n",
    "sys.path.append('/Users/nissani/Desktop/Hateful_Memes_Project/FeatureGeneration')\n",
    "import os\n",
    "import LoadingData\n",
    "from FER_featurizer import FER_Wrapper\n",
    "from hate_speech import HateWrapper\n",
    "from sentence_encoder import SentenceTransformer\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = LoadingData.LoadingData('/Users/nissani/Desktop/Hateful_Memes_Project/data/train.jsonl')\n",
    "dev_data = LoadingData.LoadingData('/Users/nissani/Desktop/Hateful_Memes_Project/data/dev.jsonl')\n",
    "image_features = LoadingData.LoadingData('/Users/nissani/Desktop/Hateful_Memes_Project/data/cleaned_getty_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = dev_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = image_features.load_data()\n",
    "image_features = image_features.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(data):\n",
    "    FER = FER_Wrapper()\n",
    "    hate = HateWrapper()\n",
    "    sentiment_classifier = TextClassifier.load('en-sentiment')\n",
    "    \n",
    "    aggregate_text = []\n",
    "    for el in data:\n",
    "        aggregate_text.append(el['text'])\n",
    "    \n",
    "    for el in data:\n",
    "        path = '/Users/nissani/Desktop/Hateful_Memes_Project/data/' + el['img']\n",
    "        emotion_feature = FER.run_FER(path)\n",
    "        img_id = el['img'].split('/')[1]\n",
    "        el['emotion_feature'] = emotion_feature[img_id]\n",
    "\n",
    "    hate_scores = hate.predict(aggregate_text)\n",
    "    for el in data:\n",
    "        el['hate_speech'] = hate_scores[hate_scores.text == el['text']].hate_speech\n",
    "        el['offensive_language'] = hate_scores[hate_scores.text == el['text']].offensive_language\n",
    "        el['neither'] = hate_scores[hate_scores.text == el['text']].neither\n",
    "\n",
    "    for el in data:\n",
    "        sentence = Sentence(el['text'])\n",
    "        sentiment_classifier.predict(sentence)\n",
    "        label = str(sentence.labels[0]).split(' ')[0]\n",
    "        proba = float(str(sentence.labels[0]).split(' ')[1].replace('(', '').replace(')', ''))\n",
    "        el['sentiment'] = [label, proba]\n",
    "        \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-25 15:43:57,265 loading file /Users/nissani/.flair/models/sentiment-en-mix-distillbert.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "25-08-2020:15:43:57,619 INFO     [configuration_utils.py:265] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at /Users/nissani/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c\n",
      "25-08-2020:15:43:57,621 INFO     [configuration_utils.py:301] Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "25-08-2020:15:43:57,784 INFO     [tokenization_utils.py:1022] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/nissani/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "featurized_train_data = create_features(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
