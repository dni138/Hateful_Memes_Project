{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import requests\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "JS_DROP_FILE = \"\"\"\n",
    "    var target = arguments[0],\n",
    "        offsetX = arguments[1],\n",
    "        offsetY = arguments[2],\n",
    "        document = target.ownerDocument || document,\n",
    "        window = document.defaultView || window;\n",
    "\n",
    "    var input = document.createElement('INPUT');\n",
    "    input.type = 'file';\n",
    "    input.onchange = function () {\n",
    "      var rect = target.getBoundingClientRect(),\n",
    "          x = rect.left + (offsetX || (rect.width >> 1)),\n",
    "          y = rect.top + (offsetY || (rect.height >> 1)),\n",
    "          dataTransfer = { files: this.files };\n",
    "\n",
    "      ['dragenter', 'dragover', 'drop'].forEach(function (name) {\n",
    "        var evt = document.createEvent('MouseEvent');\n",
    "        evt.initMouseEvent(name, !0, !0, window, 0, 0, 0, x, y, !1, !1, !1, !1, 0, null);\n",
    "        evt.dataTransfer = dataTransfer;\n",
    "        target.dispatchEvent(evt);\n",
    "      });\n",
    "\n",
    "      setTimeout(function () { document.body.removeChild(input); }, 25);\n",
    "    };\n",
    "    document.body.appendChild(input);\n",
    "    return input;\n",
    "\"\"\"\n",
    "\n",
    "def drag_and_drop_file(drop_target, path):\n",
    "    driver = drop_target.parent\n",
    "    file_input = driver.execute_script(JS_DROP_FILE, drop_target, 0, 0)\n",
    "    file_input.send_keys(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorScore(img1, img2):\n",
    "    abs_sum_error=0\n",
    "    abs_sum_error+=math.fabs(img1.T[0].mean()-img2.T[0].mean())\n",
    "    abs_sum_error+=math.fabs(img1.T[1].mean()-img2.T[1].mean())\n",
    "    abs_sum_error+=math.fabs(img1.T[2].mean()-img2.T[2].mean())\n",
    "    return abs_sum_error\n",
    "\n",
    "def keyPointScore(img1,img2):\n",
    "    orb = cv2.ORB_create() \n",
    "    queryKeypoints, queryDescriptors = orb.detectAndCompute(img1,None) \n",
    "    trainKeypoints, trainDescriptors = orb.detectAndCompute(img2,None) \n",
    "    matcher = cv2.BFMatcher() \n",
    "    matches = matcher.match(queryDescriptors,trainDescriptors) \n",
    "    sums=0.0\n",
    "    for match in matches:\n",
    "        sums+=match.distance\n",
    "    return sums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInformation(url:str):\n",
    "    \n",
    "    # Getting the webpage, creating a Response object.\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Extracting the source code of the page.\n",
    "    data = response.text\n",
    "    \n",
    "    # Passing the source code to BeautifulSoup to create a BeautifulSoup object for it.\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "        \n",
    "    caption = soup.findAll(\"div\", {\"class\": \"asset-description__caption\"})\n",
    "    tags = soup.findAll(\"li\", {\"class\": \"asset-keywords-list__item\"})\n",
    "    imgur=soup.findAll(\"img\", {\"class\": \"asset-card__image\"})\n",
    "    caption_str=\"\"\n",
    "    try:\n",
    "        caption_str:str=caption[0].getText()\n",
    "    except:\n",
    "        pass\n",
    "    tag_list:str=\",\".join([tag.getText().replace(\",\",\"\") for tag in tags])\n",
    "    img_link=imgur[0][\"src\"]\n",
    "    dictionary:{}={}\n",
    "    dictionary[\"img_url\"]=img_link\n",
    "    dictionary[\"tags\"]=tag_list\n",
    "    dictionary[\"caption\"]=caption_str\n",
    "    return  dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveImg(dir,original_img, name, urlLink):\n",
    "        if not os.path.exists(dir):\n",
    "            os.makedirs(dir) \n",
    "            \n",
    "        subpath:str= os.path.join(dir,original_img)\n",
    "        if not os.path.exists(subpath):\n",
    "            os.makedirs(subpath) \n",
    "            \n",
    "        file_name_path:str=os.path.join(subpath,name)+\".jpg\"\n",
    "        \n",
    "        img_url:str=urlLink.replace(\"?s=2048x2048\",\"\") #+\".jpg\"  \n",
    "\n",
    "        urllib.request.urlretrieve(img_url, file_name_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUN COLLECTION ON A SINGLE EXAMPLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = webdriver.Chrome('/Users/computer/PycharmProjects/anti_bullying/chromedriver')\n",
    "driver.get(\"https://www.gettyimages.co.uk/\")\n",
    "bah=driver.find_element_by_id('btnImageSearch').click()\n",
    "time.sleep(2)\n",
    "el=driver.find_element_by_css_selector(\"[ngf-drop^='dragDropUpload']\")\n",
    "path ='/Users/computer/Downloads/01235.png'\n",
    "\n",
    "drag_and_drop_file(el,path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEED TO DEAL WITH TIME OUT FOR UPLOAD OPTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topN_images=driver.find_elements_by_class_name(\"gallery-mosaic-asset__link\")\n",
    "\n",
    "max:int=6\n",
    "\n",
    "if len(topN_images)<max: max=len(topN_images)\n",
    "\n",
    "linkInfo=[]\n",
    "\n",
    "for image in topN_images[:max]:\n",
    "\n",
    "    linkInfo.append({\"url\":image.get_attribute(\"href\")})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for link in linkInfo:\n",
    "    \n",
    "   url=link[\"url\"]\n",
    "   print(url)\n",
    "   time.sleep(3)\n",
    "   link.update(getInformation(url))\n",
    "   print(\"next\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAVE POSSIBLE IMAGE MATCHES AND THEIR TAGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectPath=\"/Users/computer/Downloads/Hateful_Memes_Project/ExampleProject\"\n",
    "elementName=\"01235.png\"#the original png\n",
    "\n",
    "for counter,link in zip([i for i in range(len(linkInfo))],linkInfo):\n",
    "    link[\"src\"]=elementName\n",
    "    link[\"id\"]=str(counter+1)\n",
    "    time.sleep(2)\n",
    "    print(\"saving Image\")\n",
    "    saveImg(projectPath,elementName,link[\"id\"],link[\"img_url\"])\n",
    "\n",
    "print (\"saving Misc Info as a clean csv file\")\n",
    "\n",
    "subpath:str= os.path.join(projectPath,elementName) #directory to save\n",
    "all_info=pd.DataFrame(linkInfo)\n",
    "all_info.to_csv(os.path.join(subpath,\"related_info.tsv\"),sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find out which is the true image SEE Test_Similarity.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####SEEE Test Similarity Script - this is broken :(\n",
    "src_img = cv2.imread(original.replace(\".png\",\"\"), cv2.IMREAD_COLOR)  # trainImage\n",
    "color_scores=[]\n",
    "key_point_scores=[]\n",
    "for img_name in target_imgs:\n",
    "    img1 = cv2.imread(original.replace(\".png\",\"\")+\"/\"+str(img_name)+\".jpg\", cv2.IMREAD_COLOR)           # queryImage\n",
    "\n",
    "    img1=cv2.resize(img1,(500,500))\n",
    "    img2=cv2.resize(src_img,(500,500))\n",
    "    \n",
    "    color_score=colorScore(img1,img2)\n",
    "    key_point_score=keyPointScore(img1,img2)\n",
    "    color_scores.append(color_score)\n",
    "    key_point_scores.append(key_point_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following paths are ignored by one of your .gitignore files:\n",
      "ExampleProject/model-outputs\n",
      "ExampleProject/submission.csv\n",
      "Use -f if you really want to add them.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
